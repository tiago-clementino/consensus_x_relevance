{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Ambiente\n",
    "\n",
    "Bibliotecas utilizadas:\n",
    "\n",
    "- **NLTK**, para geração de *tokens*.\n",
    "- **Matplotlib** e **Seaborn**, para criação de gráficos.\n",
    "- **Pandas** e **NumPy**, para estatísticas.\n",
    "- **RE**, para filtragem através de expressões regulares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\tclem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tclem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tclem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "nltk.download('rslp')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Opinion</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Urgency</th>\n",
       "      <th>CourseType</th>\n",
       "      <th>forumpostid</th>\n",
       "      <th>coursedisplayname</th>\n",
       "      <th>forumuid</th>\n",
       "      <th>createdat</th>\n",
       "      <th>posttype</th>\n",
       "      <th>anonymous</th>\n",
       "      <th>anonymoustopeers</th>\n",
       "      <th>upcount</th>\n",
       "      <th>commentthreadid</th>\n",
       "      <th>reads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Interesting! How often we say those things to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6,5</td>\n",
       "      <td>2</td>\n",
       "      <td>1,5</td>\n",
       "      <td>Education</td>\n",
       "      <td>5225177f2c501f0a00000015</td>\n",
       "      <td>Education/EDUC115N/How_to_Learn_Math</td>\n",
       "      <td>30CADB93E6DE4711193D7BD05F2AE95C</td>\n",
       "      <td>02/09/2013 22:55</td>\n",
       "      <td>Comment</td>\n",
       "      <td>FALSO</td>\n",
       "      <td>FALSO</td>\n",
       "      <td>0</td>\n",
       "      <td>5221a8262cfae31200000001</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>What is \\Algebra as a Math Game\\'''' or are yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3,5</td>\n",
       "      <td>Education</td>\n",
       "      <td>5207d0e9935dfc0e0000005e</td>\n",
       "      <td>Education/EDUC115N/How_to_Learn_Math</td>\n",
       "      <td>37D8FAEE7D0B94B6CFC57D98FD3D0BA5</td>\n",
       "      <td>11/08/2013 17:59</td>\n",
       "      <td>Comment</td>\n",
       "      <td>FALSO</td>\n",
       "      <td>FALSO</td>\n",
       "      <td>0</td>\n",
       "      <td>520663839df35b0a00000043</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I like the idea of my kids principal who says ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5,5</td>\n",
       "      <td>3</td>\n",
       "      <td>2,5</td>\n",
       "      <td>Education</td>\n",
       "      <td>52052c82d01fec0a00000071</td>\n",
       "      <td>Education/EDUC115N/How_to_Learn_Math</td>\n",
       "      <td>CC11480215042B3EB6E5905EAB13B733</td>\n",
       "      <td>09/08/2013 17:53</td>\n",
       "      <td>Comment</td>\n",
       "      <td>FALSO</td>\n",
       "      <td>FALSO</td>\n",
       "      <td>0</td>\n",
       "      <td>51e59415e339d716000001a6</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>From their responses, it seems the students re...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2,5</td>\n",
       "      <td>Education</td>\n",
       "      <td>5240a45e067ebf1200000008</td>\n",
       "      <td>Education/EDUC115N/How_to_Learn_Math</td>\n",
       "      <td>C717F838D10E8256D7C88B33C43623F1</td>\n",
       "      <td>23/09/2013 20:28</td>\n",
       "      <td>CommentThread</td>\n",
       "      <td>FALSO</td>\n",
       "      <td>FALSO</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The boys loved math, because \\there is freedom...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Education</td>\n",
       "      <td>5212c5e2dd10251500000062</td>\n",
       "      <td>Education/EDUC115N/How_to_Learn_Math</td>\n",
       "      <td>F83887D68EA48964687C6441782CDD0E</td>\n",
       "      <td>20/08/2013 01:26</td>\n",
       "      <td>CommentThread</td>\n",
       "      <td>FALSO</td>\n",
       "      <td>FALSO</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Opinion  Question  \\\n",
       "0  Interesting! How often we say those things to ...        1         0   \n",
       "1  What is \\Algebra as a Math Game\\'''' or are yo...        0         1   \n",
       "2  I like the idea of my kids principal who says ...        1         0   \n",
       "3  From their responses, it seems the students re...        1         0   \n",
       "4  The boys loved math, because \\there is freedom...        1         0   \n",
       "\n",
       "   Answer Sentiment Confusion Urgency CourseType               forumpostid  \\\n",
       "0       0       6,5         2     1,5  Education  5225177f2c501f0a00000015   \n",
       "1       0         4         5     3,5  Education  5207d0e9935dfc0e0000005e   \n",
       "2       0       5,5         3     2,5  Education  52052c82d01fec0a00000071   \n",
       "3       0         6         3     2,5  Education  5240a45e067ebf1200000008   \n",
       "4       0         7         2       3  Education  5212c5e2dd10251500000062   \n",
       "\n",
       "                      coursedisplayname                          forumuid  \\\n",
       "0  Education/EDUC115N/How_to_Learn_Math  30CADB93E6DE4711193D7BD05F2AE95C   \n",
       "1  Education/EDUC115N/How_to_Learn_Math  37D8FAEE7D0B94B6CFC57D98FD3D0BA5   \n",
       "2  Education/EDUC115N/How_to_Learn_Math  CC11480215042B3EB6E5905EAB13B733   \n",
       "3  Education/EDUC115N/How_to_Learn_Math  C717F838D10E8256D7C88B33C43623F1   \n",
       "4  Education/EDUC115N/How_to_Learn_Math  F83887D68EA48964687C6441782CDD0E   \n",
       "\n",
       "          createdat       posttype anonymous anonymoustopeers  upcount  \\\n",
       "0  02/09/2013 22:55        Comment     FALSO            FALSO        0   \n",
       "1  11/08/2013 17:59        Comment     FALSO            FALSO        0   \n",
       "2  09/08/2013 17:53        Comment     FALSO            FALSO        0   \n",
       "3  23/09/2013 20:28  CommentThread     FALSO            FALSO        0   \n",
       "4  20/08/2013 01:26  CommentThread     FALSO            FALSO        0   \n",
       "\n",
       "            commentthreadid  reads  \n",
       "0  5221a8262cfae31200000001     41  \n",
       "1  520663839df35b0a00000043     55  \n",
       "2  51e59415e339d716000001a6     25  \n",
       "3                      None      0  \n",
       "4                      None      3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import re\n",
    "#from unidecode import unidecode\n",
    "#import unicodedata as ud\n",
    "\n",
    "RESULTS_CSV = '..\\data\\stanford\\in.csv'\n",
    "data = pd.read_csv(RESULTS_CSV).replace(np.nan, \"\", regex = True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "commentthreadid\n",
       "5,26331E+23                 I am after second review. Although I had appli...\n",
       "5,26331E+23                 Also got that. Are you going to resubmit and s...\n",
       "5,26331E+23                 I don't think the system is fair - some review...\n",
       "5,30483E+23                 Thanks. It was useful to think about the answe...\n",
       "51b513008e8d330d00000001    Hello Kristin Thank you for this very nice and...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings = pd.DataFrame(data={'Opinion': data['Opinion'], \n",
    "                              'Question': data['Question'], \n",
    "                              'Answer': data['Answer'], \n",
    "                              'Sentiment': data['Sentiment'], \n",
    "                              'Confusion': data['Confusion'], \n",
    "                              'Urgency': data['Urgency'], \n",
    "                              'Text': data['Text'], \n",
    "                              'forumpostid': data['forumpostid'], \n",
    "                              'CourseType': data['CourseType'], \n",
    "                              'coursedisplayname': data['coursedisplayname'], \n",
    "                              'commentthreadid': [row['forumpostid'] if row['commentthreadid'] == 'None' or row['commentthreadid'] == '' else row['commentthreadid'] for index, row in data.iterrows()]})\n",
    "\n",
    "postings.set_index(['commentthreadid'],inplace=True,drop=True)\n",
    "postings.sort_values(by=['commentthreadid'],inplace=True)\n",
    "\n",
    "postings_aux = postings.groupby('commentthreadid')\n",
    "\n",
    "discussions = pd.DataFrame(data={'discussion': postings_aux['Text'].sum(), 'CourseType': postings_aux['CourseType'].first(), 'coursedisplayname': postings_aux['coursedisplayname'].first()})#, 'commentthreadid': data_cleanned.groupby('commentthreadid').first().index}) \n",
    "\n",
    "#data_cleanned.reset_index(inplace=True)\n",
    "#data_cleanned.drop(['index'], axis=1, inplace=True)\n",
    "#print(re.sub(rb'[^\\x00-\\x7f]',rb' ',discussions.loc['51b513008e8d330d00000001','discussion'].encode('utf-8')))\n",
    "\n",
    "#print(re.sub(r'[^\\x00-\\x7f]',r' ',ud.normalize('NFD',discussions.loc['51b513008e8d330d00000001','discussion'])))\n",
    "\n",
    "#print(discussions.loc['51b513008e8d330d00000001','discussion']) \n",
    "postings['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I am after second review. Although I had appli...\n",
       "1    Also got that. Are you going to resubmit and s...\n",
       "2    I don't think the system is fair - some review...\n",
       "3    Thanks. It was useful to think about the answe...\n",
       "4    Hello Kristin Thank you for this very nice and...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings.reset_index(inplace=False)['Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenização\n",
    "\n",
    "Inicialmente, foram definidas as estratégias de tokenização que seriam adotadas para, a partir daí, gerar os tokens que serão utilizados nas análises. A primeira estratégia adotada foi a **remoção das _stopwords_**. Essa remoção foi realizada através da coleção de palavras disponibilizada pela biblioteca NLTK e é motivada pelo fato que, apesar de sua frequência elevada, as _stopwords_ são pouco significantes para os textos.\n",
    "\n",
    "As palavras adotadas como *tokens* foram mantidas respeitando a **bicameralidade** (caixa alta ou baixa), visando preservar as possíveis diferenças sintáticas. Também foram mantidas todas as palavras com **duas ou mais letras** e considerou-se que **hifens** e **apóstrofos** são caracteres integrantes das palavras.\n",
    "\n",
    "Também foram utilizados, como *tokens*, os números inteiros e decimais com, pelo menos, **dois dígitos** e datas no formato **dd/mm/yy** ou **dd/mm/yyyy**, dada a importância que esses valores podem ter para o texto, ainda que uma possível vetorização possa vir a descartá-los.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_patterns = { \"words\": '''\\w+[-']*\\w+''',\n",
    "                  \"discrete\": '''\\d{2,}''',\n",
    "                  \"dates\": '''\\d{2}\\/\\d{2}\\/\\d{2,4}''',\n",
    "                  \"continuous\": '''\\d*[\\.]*\\d+[\\.|\\,]*\\d+''' }\n",
    "\n",
    "regex = '|'.join(regex_patterns.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data, regex):\n",
    "    \n",
    "    token_list = []\n",
    "    token_bag = []\n",
    "    tokenizer = RegexpTokenizer(regex)\n",
    "    stopwords_en = stopwords.words(\"english\")\n",
    "  \n",
    "    for row in data:\n",
    "        \n",
    "        tokens = tokenizer.tokenize(row)\n",
    "        tokens = [token for token in tokens if token not in stopwords_en]\n",
    "        token_bag.extend(tokens)\n",
    "        token_list.append(tokens)\n",
    "      \n",
    "    return token_list, token_bag\n",
    "\n",
    "postings['Text'], corpus_vocabulary = tokenize_data(postings['Text'], regex)\n",
    "corpus_vocabulary_set = set(corpus_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opinion</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Urgency</th>\n",
       "      <th>Text</th>\n",
       "      <th>forumpostid</th>\n",
       "      <th>CourseType</th>\n",
       "      <th>coursedisplayname</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commentthreadid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5,26331E+23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[second, review, Although, applied, comments, ...</td>\n",
       "      <td>526563a587050a90ef000006</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Medicine/SciWrite/Fall2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5,26331E+23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4,5</td>\n",
       "      <td>[Also, got, Are, going, resubmit, see, get, be...</td>\n",
       "      <td>5264e2152cc6095e83000015</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Medicine/SciWrite/Fall2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5,26331E+23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5,5</td>\n",
       "      <td>[think, system, fair, reviewers, rush, process...</td>\n",
       "      <td>5263a0de9ec9282178000010</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Medicine/SciWrite/Fall2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5,30483E+23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[Thanks, It, useful, think, answers, Corey, ge...</td>\n",
       "      <td>5,30483E+23</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>HumanitiesSciences/EP101/Environmental_Physiology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51b513008e8d330d00000001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3,5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>[Hello, Kristin, Thank, nice, usefull, Mooc, U...</td>\n",
       "      <td>53e1dfb0fac7aaea13000007</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Medicine/HRP258/Statistics_in_Medicine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Opinion  Question  Answer Sentiment Confusion  \\\n",
       "commentthreadid                                                           \n",
       "5,26331E+23                     1         0       1         4         4   \n",
       "5,26331E+23                     0         1       1         4         4   \n",
       "5,26331E+23                     1         0       0         3         4   \n",
       "5,30483E+23                     0         0       0         5         4   \n",
       "51b513008e8d330d00000001        0         1       0       3,5         4   \n",
       "\n",
       "                         Urgency  \\\n",
       "commentthreadid                    \n",
       "5,26331E+23                    3   \n",
       "5,26331E+23                  4,5   \n",
       "5,26331E+23                  5,5   \n",
       "5,30483E+23                    2   \n",
       "51b513008e8d330d00000001       5   \n",
       "\n",
       "                                                                       Text  \\\n",
       "commentthreadid                                                               \n",
       "5,26331E+23               [second, review, Although, applied, comments, ...   \n",
       "5,26331E+23               [Also, got, Are, going, resubmit, see, get, be...   \n",
       "5,26331E+23               [think, system, fair, reviewers, rush, process...   \n",
       "5,30483E+23               [Thanks, It, useful, think, answers, Corey, ge...   \n",
       "51b513008e8d330d00000001  [Hello, Kristin, Thank, nice, usefull, Mooc, U...   \n",
       "\n",
       "                                       forumpostid  CourseType  \\\n",
       "commentthreadid                                                  \n",
       "5,26331E+23               526563a587050a90ef000006    Medicine   \n",
       "5,26331E+23               5264e2152cc6095e83000015    Medicine   \n",
       "5,26331E+23               5263a0de9ec9282178000010    Medicine   \n",
       "5,30483E+23                            5,30483E+23  Humanities   \n",
       "51b513008e8d330d00000001  53e1dfb0fac7aaea13000007    Medicine   \n",
       "\n",
       "                                                          coursedisplayname  \n",
       "commentthreadid                                                              \n",
       "5,26331E+23                                      Medicine/SciWrite/Fall2013  \n",
       "5,26331E+23                                      Medicine/SciWrite/Fall2013  \n",
       "5,26331E+23                                      Medicine/SciWrite/Fall2013  \n",
       "5,30483E+23               HumanitiesSciences/EP101/Environmental_Physiology  \n",
       "51b513008e8d330d00000001             Medicine/HRP258/Statistics_in_Medicine  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conhecendo os *tokens* e o vocabulário do *corpus* é possível calcular as métricas restantes e necessárias para analisar a frequência das palavras no *corpus*. Nesse processo será produzida um *Series* com as frequências das palavras que será reutilizado e complementado posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_series(tokens):\n",
    "  token_frequency = pd.Series(tokens).value_counts().reset_index()\n",
    "  token_frequency.columns = [\"Word\", \"Frequency\"]\n",
    "  return token_frequency\n",
    "\n",
    "total_word_occurrences = len(corpus_vocabulary)\n",
    "words_frequency = get_frequency_series(corpus_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que as características do *corpus* utilizado estão bem definidas, há interesse em conhecer como se comporta a distribuição de frequência das palavras nele contidas. Para isso, o *series* criado anteriormente descrevendo a frequência de todas as palavras do vocabulário será complementado com as novas variáveis de interesse. Além da frequência absoluta de cada palavra, serão também analisados:\n",
    "\n",
    "- **r:** O *rank* das palavras em relação à sua frequência\n",
    "- **Pr:** A probabilidade de ocorrência da das palavras\n",
    "- **r.Pr:** Os resultados da Lei de Zipf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_frequency[\"Ranking (r)\"] = words_frequency[\"Frequency\"].rank(ascending=False, method='first')\n",
    "pr = (words_frequency[\"Frequency\"] / total_word_occurrences)\n",
    "r_pr = (words_frequency[\"Ranking (r)\"] * pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para melhor compreensão do leitor, são realizados alguns ajustes de apresentação para os valores calculados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_frequency[\"Ranking (r)\"] = words_frequency[\"Ranking (r)\"].astype(int)\n",
    "words_frequency[\"Pr (%)\"] = round(pr * 100, 2)\n",
    "words_frequency[\"r.Pr\"] = round(r_pr, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, devido à grande quantidade de palavras no vocabulário do *corpus*, a tabela abaixo descreve apenas os resultados obtidos para as 50 palavras mais frequentes da coleção de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Ranking (r)</th>\n",
       "      <th>Pr (%)</th>\n",
       "      <th>r.Pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>students</td>\n",
       "      <td>8709</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>would</td>\n",
       "      <td>6188</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The</td>\n",
       "      <td>6161</td>\n",
       "      <td>3</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>math</td>\n",
       "      <td>5954</td>\n",
       "      <td>4</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>think</td>\n",
       "      <td>5260</td>\n",
       "      <td>5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>one</td>\n",
       "      <td>5036</td>\n",
       "      <td>6</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>course</td>\n",
       "      <td>4279</td>\n",
       "      <td>7</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>like</td>\n",
       "      <td>4012</td>\n",
       "      <td>8</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>It</td>\n",
       "      <td>3926</td>\n",
       "      <td>9</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>also</td>\n",
       "      <td>3867</td>\n",
       "      <td>10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>get</td>\n",
       "      <td>3842</td>\n",
       "      <td>11</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>zipRedac</td>\n",
       "      <td>3761</td>\n",
       "      <td>12</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>see</td>\n",
       "      <td>3636</td>\n",
       "      <td>13</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>way</td>\n",
       "      <td>3444</td>\n",
       "      <td>14</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>work</td>\n",
       "      <td>3344</td>\n",
       "      <td>15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>time</td>\n",
       "      <td>3330</td>\n",
       "      <td>16</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>problem</td>\n",
       "      <td>3132</td>\n",
       "      <td>17</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>make</td>\n",
       "      <td>3108</td>\n",
       "      <td>18</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>This</td>\n",
       "      <td>3092</td>\n",
       "      <td>19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>class</td>\n",
       "      <td>2935</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>know</td>\n",
       "      <td>2871</td>\n",
       "      <td>21</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>I'm</td>\n",
       "      <td>2842</td>\n",
       "      <td>22</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>different</td>\n",
       "      <td>2806</td>\n",
       "      <td>23</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>many</td>\n",
       "      <td>2733</td>\n",
       "      <td>24</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>mistakes</td>\n",
       "      <td>2701</td>\n",
       "      <td>25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>really</td>\n",
       "      <td>2688</td>\n",
       "      <td>26</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>use</td>\n",
       "      <td>2639</td>\n",
       "      <td>27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>answer</td>\n",
       "      <td>2601</td>\n",
       "      <td>28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>could</td>\n",
       "      <td>2537</td>\n",
       "      <td>29</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>people</td>\n",
       "      <td>2519</td>\n",
       "      <td>30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>school</td>\n",
       "      <td>2485</td>\n",
       "      <td>31</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>help</td>\n",
       "      <td>2427</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>In</td>\n",
       "      <td>2416</td>\n",
       "      <td>33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>If</td>\n",
       "      <td>2395</td>\n",
       "      <td>34</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>need</td>\n",
       "      <td>2361</td>\n",
       "      <td>35</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>learning</td>\n",
       "      <td>2333</td>\n",
       "      <td>36</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>women</td>\n",
       "      <td>2287</td>\n",
       "      <td>37</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>good</td>\n",
       "      <td>2284</td>\n",
       "      <td>38</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>question</td>\n",
       "      <td>2232</td>\n",
       "      <td>39</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>much</td>\n",
       "      <td>2209</td>\n",
       "      <td>40</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>data</td>\n",
       "      <td>2180</td>\n",
       "      <td>41</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>anon_screen_name_redacted</td>\n",
       "      <td>2137</td>\n",
       "      <td>42</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>nameRedac_</td>\n",
       "      <td>2136</td>\n",
       "      <td>43</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>first</td>\n",
       "      <td>2125</td>\n",
       "      <td>44</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>2117</td>\n",
       "      <td>45</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>learn</td>\n",
       "      <td>2012</td>\n",
       "      <td>46</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>well</td>\n",
       "      <td>1909</td>\n",
       "      <td>47</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>want</td>\n",
       "      <td>1899</td>\n",
       "      <td>48</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>year</td>\n",
       "      <td>1875</td>\n",
       "      <td>49</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>may</td>\n",
       "      <td>1865</td>\n",
       "      <td>50</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Word  Frequency  Ranking (r)  Pr (%)   r.Pr\n",
       "0                    students       8709            1    0.90  0.009\n",
       "1                       would       6188            2    0.64  0.013\n",
       "2                         The       6161            3    0.64  0.019\n",
       "3                        math       5954            4    0.62  0.025\n",
       "4                       think       5260            5    0.55  0.027\n",
       "5                         one       5036            6    0.52  0.031\n",
       "6                      course       4279            7    0.44  0.031\n",
       "7                        like       4012            8    0.42  0.033\n",
       "8                          It       3926            9    0.41  0.037\n",
       "9                        also       3867           10    0.40  0.040\n",
       "10                        get       3842           11    0.40  0.044\n",
       "11                   zipRedac       3761           12    0.39  0.047\n",
       "12                        see       3636           13    0.38  0.049\n",
       "13                        way       3444           14    0.36  0.050\n",
       "14                       work       3344           15    0.35  0.052\n",
       "15                       time       3330           16    0.35  0.055\n",
       "16                    problem       3132           17    0.33  0.055\n",
       "17                       make       3108           18    0.32  0.058\n",
       "18                       This       3092           19    0.32  0.061\n",
       "19                      class       2935           20    0.30  0.061\n",
       "20                       know       2871           21    0.30  0.063\n",
       "21                        I'm       2842           22    0.30  0.065\n",
       "22                  different       2806           23    0.29  0.067\n",
       "23                       many       2733           24    0.28  0.068\n",
       "24                   mistakes       2701           25    0.28  0.070\n",
       "25                     really       2688           26    0.28  0.073\n",
       "26                        use       2639           27    0.27  0.074\n",
       "27                     answer       2601           28    0.27  0.076\n",
       "28                      could       2537           29    0.26  0.076\n",
       "29                     people       2519           30    0.26  0.079\n",
       "30                     school       2485           31    0.26  0.080\n",
       "31                       help       2427           32    0.25  0.081\n",
       "32                         In       2416           33    0.25  0.083\n",
       "33                         If       2395           34    0.25  0.085\n",
       "34                       need       2361           35    0.25  0.086\n",
       "35                   learning       2333           36    0.24  0.087\n",
       "36                      women       2287           37    0.24  0.088\n",
       "37                       good       2284           38    0.24  0.090\n",
       "38                   question       2232           39    0.23  0.090\n",
       "39                       much       2209           40    0.23  0.092\n",
       "40                       data       2180           41    0.23  0.093\n",
       "41  anon_screen_name_redacted       2137           42    0.22  0.093\n",
       "42                 nameRedac_       2136           43    0.22  0.095\n",
       "43                      first       2125           44    0.22  0.097\n",
       "44                     Thanks       2117           45    0.22  0.099\n",
       "45                      learn       2012           46    0.21  0.096\n",
       "46                       well       1909           47    0.20  0.093\n",
       "47                       want       1899           48    0.20  0.095\n",
       "48                       year       1875           49    0.19  0.095\n",
       "49                        may       1865           50    0.19  0.097"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words_frequency = pd.DataFrame(words_frequency)\n",
    "df_words_frequency.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "postings.reset_index().to_json(r'..\\data\\stanford\\postings.json')\n",
    "discussions.to_json(r'..\\data\\stanford\\discussions.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
